from pathlib import Path

import streamlit as st
from PIL import Image


# --- PATH SETTINGS ---
current_dir = Path(__file__).parent if "__file__" in locals() else Path.cwd()
css_file = current_dir / "styles" / "main.css"
resume_file = current_dir / "assets" / "CV.pdf"
profile_pic = current_dir / "assets" / "profile-pic.png"


# --- GENERAL SETTINGS ---
PAGE_TITLE = "Digital CV | George Cubas"
PAGE_ICON = ":wave:"
NAME = "George Cubas"
DESCRIPTION = """
Mid Level Data Analyst, assisting enterprises by supporting data-driven decision-making.
"""
EMAIL = "georgeraulc@email.com"
SOCIAL_MEDIA = {
    "LinkedIn": "https://www.linkedin.com/in/george-cubas-55113a29/",
    "GitHub": "https://github.com/mateBarey",
}
#remember to add a selenium crawler and beautifulsoup code
PROJECTS = {
    "üèÜ DB as Rest API - A db using REST using Flask allows users to register and store data": "https://github.com/mateBarey/DB-as-a-Rest-API-using-Flask",
    "üèÜ Apache Spark Prediction Pipeline - use IOT data and spark to predict Pressure": "https://github.com/mateBarey/Apache-Spark-IOT-Prediction-Pipeline",
    "üèÜ Trading Backtester - Uses Trading API to paper test MACD strategy ": "https://github.com/mateBarey/Trading-Backtester-Ribbon-Strategy",

}

TRAINING_AND_CERT = {
    "üèÜ IBM - AI Engineering Professional": "https://github.com/mateBarey/Apache-Spark-IOT-Prediction-Pipeline",
    "üèÜ Google - Machine Learning ": "https://www.coursera.org/account/accomplishments/specialization/certificate/P57BYGZPYANV",
    "üèÜ Google - Reinforcement Learning ": "https://www.coursera.org/account/accomplishments/certificate/AGP9TE8AFPSC",

}

st.set_page_config(page_title=PAGE_TITLE, page_icon=PAGE_ICON)


# --- LOAD CSS, PDF & PROFIL PIC ---
with open(css_file) as f:
    st.markdown("<style>{}</style>".format(f.read()), unsafe_allow_html=True)
with open(resume_file, "rb") as pdf_file:
    PDFbyte = pdf_file.read()
profile_pic = Image.open(profile_pic)


# --- HERO SECTION ---
col1, col2 = st.columns(2)
with col1:
    st.image(profile_pic, width=230)

with col2:
    st.title(NAME)
    st.write(DESCRIPTION)
    st.download_button(
        label=" üìÑ Download Resume",
        data=PDFbyte,
        file_name=resume_file.name,
        mime="application/octet-stream",
    )
    st.write("üì´", EMAIL)


# --- SOCIAL LINKS ---
st.write('\n')
cols = st.columns(len(SOCIAL_MEDIA))
for index, (platform, link) in enumerate(SOCIAL_MEDIA.items()):
    cols[index].write(f"[{platform}]({link})")


# --- EXPERIENCE & QUALIFICATIONS ---
st.write('\n')
st.subheader("Experience & Qulifications")
st.write(
    """
- ‚úîÔ∏è 5+ Years expereince extracting actionable insights from data
- ‚úîÔ∏è Strong hands on experience and knowledge in Python and SQL
- ‚úîÔ∏è Good understanding of statistical principles and their respective applications
- ‚úîÔ∏è Excellent team-player and displaying strong sense of initiative on tasks
"""
)


# --- SKILLS ---
st.write('\n')
st.subheader("Hard Skills")
st.write(
    """
- üë©‚Äçüíª Programming: Python (Scikit-learn, Pandas), SQL, VBA, R, Ruby, C#
- üìä Data Visulization: Dash,Streamlit, MS Excel, Plotly
- üìö Modeling: Logistic regression, linear regression, Classifiers, Neural Nets
- üóÑÔ∏è Databases: Postgres, MongoDB, MySQL
"""
)


# --- WORK HISTORY ---
st.write('\n')
st.subheader("Work History")
st.write("---")

# --- JOB 1
st.write("üöß", "**Python Developer | University of Virginia**")
st.write("03/2022 - 12/2022")
st.write(
    """
- ‚ñ∫ Generate programs for ETL process for Office of Sponsored Programs
- ‚ñ∫ Utilize Pandas , nosql and sqlalchemy to streamline the ETL process for Awards, Proposals and agreements data for full end to end Project implementation using analysis, design, modeling and testing for server side scripts and applications.
- ‚ñ∫ Build crawlers to verify the quality of the frontend data and see what percentage of data needs to be corrected
- ‚ñ∫ Use Multiprocessing(bypassing GIL) and asyncio modules when applicable for parallelization/concurrent  performance in various scripts
"""
)

# --- JOB 2
st.write('\n')
st.write("üöß", "**Python Developer | Kinstone Investment Properties**")
st.write("07/2019 - 03/2022")
st.write(
    """
- ‚ñ∫ Model valuation and acquisition of new properties using Pandas, NumPy and Sci-kitlearn in Jupyter Notebook
- ‚ñ∫ Utilize BeautifulSoup and Selenium to scrape Freddie Mac Multi Family Index information and Case Shiller Housing Price index information adjusted for real inflation. Construct Bridge API‚Äôs to schedule updated cost valuations for properties in certain areas of Houston using the Zillow API.
- ‚ñ∫ Apply Monte Carlo Analysis using NumPy for building a real time and cost estimate for predicting a Levered and Unlevered IRR.
"""
)

# --- JOB 3
st.write('\n')
st.write("üöß", "**Python Engineer | Mass Action Engineering**")
st.write("01/2019 - 07/2019")
st.write(
    """
- ‚ñ∫Created Python scripts for processing all P & ID's and PFD's .
- ‚ñ∫ Designed a process calculation utilizing NumPy, Pandas and Jupyter Notebook. The scripts were modularized to have each unit process within its own class using OOP principles.
- ‚ñ∫ Worked with a tech team to effectively simulate the Free Radical Emulsion Polymerization of the monomer Vinylidene Fluoride.
"""
)

# --- JOB 4
st.write('\n')
st.write("üöß", "**Python Engineer | Occidental Petroleum**")
st.write("01/2019 - 07/2019")
st.write(
    """
- ‚ñ∫ Planned various Field Development and Section Development plans in NM and TX areas.
- ‚ñ∫ Built an Anti-Collision Risk Analysis Web application using Django Framework that calculated the risk between Planned Well Spreadsheet and Existing wells.
- ‚ñ∫ Created a script that used a pretrained Neural network to extract Scanned Well File Data to a csv using a Linux shell script.
- ‚ñ∫ Built scrapers using beautifulsoup4 and Selenium.
- ‚ñ∫ Designed a drilling web application using Django and a machine learning algorithm¬†that modeled drawdown for Production using Scikit-learn.
- ‚ñ∫ Developed models using ArcGIS, Python, Arcpy , SQL, Excel
"""
)

# --- Projects & Accomplishments ---
st.write('\n')
st.subheader("Projects ")
st.write("---")
for project, link in PROJECTS.items():
    st.write(f"[{project}]({link})")

# --- Projects & Accomplishments ---
st.write('\n')
st.subheader("Training and Certifications ")
st.write("---")
for project, link in PROJECTS.items():
    st.write(f"[{project}]({link})")
